{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d04c76d",
   "metadata": {},
   "source": [
    "# Table 2 \n",
    "Internal Training/Optimal Model Selection - Performance summary of Decision Trees Classifier on F1||F5 and F5/F1 Delta Radiomics Models with and without Auxiliary Data.\n",
    "\n",
    "# Table 3\n",
    "External Testing -  Performance Summary of Decision Trees Classifier on the External Adrenal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb8b7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "# import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV,ParameterGrid\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score,roc_auc_score,classification_report\n",
    "from sklearn.model_selection import KFold,cross_val_score,cross_validate, cross_val_predict,RepeatedKFold, StratifiedKFold,RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from random import randrange, uniform\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import BorderlineSMOTE,SVMSMOTE,SMOTEN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64210783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "\n",
    "AdrenalData = pd.read_excel(\"Path to Internal Adrenal Dataset Delta features\")\n",
    "LungData = pd.read_excel(\"Path to Internal Lung Dataset Delta features\")\n",
    "PancreasData = pd.read_excel(\"Path to Internal Pancreas Dataset Delta features\")\n",
    "\n",
    "# Define the target and feature vectors in the dataset\n",
    "\n",
    "Adrenal_Ytrain = AdrenalData.iloc[:,0] # use the slicing value that applies to your data\n",
    "Adrenal_Xtrain = AdrenalData.iloc[:,1:]\n",
    "\n",
    "Lung_Ytrain = LungData.iloc[:,1]\n",
    "Lung_Xtrain = LungData[:,2:]\n",
    "\n",
    "\n",
    "pancreas_Ytrain = PancreasData.iloc[:,1]\n",
    "pancreas_Xtrain = PancreasData.iloc[:,2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9d5800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "# Bootstrap Function\n",
    "def Bootstrap(x, y, n_split, random_seed=42):\n",
    "    import numpy as np\n",
    "    np.random.seed(42)\n",
    "    rng = np.random.RandomState(random_seed)\n",
    "    sample_idx = np.arange(x.shape[0])\n",
    "    set_idx = set(sample_idx)\n",
    "    Train_id={}\n",
    "    Test_id={}\n",
    "    for i in range(n_split):\n",
    "        while True:\n",
    "            train_idx= rng.choice(sample_idx[y==1],\n",
    "                                   size=np.sum(y),\n",
    "                                   replace=True)\n",
    "            train_idx= np.append(train_idx, rng.choice(sample_idx[y==0],\n",
    "                                   size=np.sum(1-y),\n",
    "                                   replace=True))\n",
    "            \n",
    "            if len(set(sample_idx[y==1]).difference(set(train_idx))) and len(set(sample_idx[y==0]).difference(set(train_idx))):\n",
    "                break\n",
    "        test_idx = np.array(list(set_idx - set(train_idx)))\n",
    "        Train_id[i]=train_idx\n",
    "        Test_id[i]=test_idx\n",
    "            \n",
    "    return Train_id, Test_id  \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Grid for Feature Selection and Hyperparameter Tuning\n",
    "\n",
    "# Feel free to modify\n",
    "\n",
    "# ElasticNet Feature Selection Parameter Grid and Pipleline\n",
    "param_grid_EN = {\n",
    "    'model__alpha': [0.1],\n",
    "    'model__l1_ratio':[0.4],\n",
    "}\n",
    "\n",
    "pipeline_EN = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', ElasticNet())\n",
    "        ])\n",
    "\n",
    "\n",
    "# Machine Learning Classifiers\n",
    "\n",
    "classifiers = {\n",
    "    \"DT\": DecisionTreeClassifier()     \n",
    "    }\n",
    "\n",
    "# Classifier Pipelines\n",
    "\n",
    "pipelines = {}\n",
    "for name, classifier in classifiers.items():\n",
    "    pipeline = Pipeline([\n",
    "        (\"classifier\", classifier)\n",
    "    ])\n",
    "    \n",
    "    pipelines[name] = pipeline\n",
    "\n",
    "# Parameter grids for classifiers\n",
    "params = {\n",
    "    \"DT\": {\n",
    "        'classifier__max_depth': np.arange(2, 10, 1),\n",
    "        'classifier__criterion': ['gini', 'entropy'],\n",
    "        'classifier__min_samples_split': np.arange(2, 5, 1),\n",
    "        'classifier__min_samples_leaf': np.arange(2, 5, 1),\n",
    "        'classifier__random_state': [0,1,10,42],\n",
    "        \n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3066ff7",
   "metadata": {},
   "source": [
    "# Model Development \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec0e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the Adrenal Data into 42 Bootstrapped Train and Test folds\n",
    "\n",
    "Train_id, Test_id = Bootstrap(Adrenal_Xtrain, Adrenal_Ytrain, n_split=42, random_seed=42)\n",
    "\n",
    "# Define inner cross-validation fold\n",
    "\n",
    "inner_kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Feature selection, Hyperparameter tuning and best estimator selection.\n",
    "\n",
    "best_estimators = []  # List of the best estimators after hyperparameter tuning\n",
    "\n",
    "\n",
    "for i in range(len(Train_id)):\n",
    "    X_train, y_train = Adrenal_Xtrain.iloc[Train_id[i]], Adrenal_Ytrain.iloc[Train_id[i]]\n",
    "    X_test, y_test = Adrenal_Xtrain.iloc[Test_id[i]], Adrenal_Ytrain.iloc[Test_id[i]]\n",
    "    \n",
    "    # Feature Selection\n",
    "    # Note that feature selection is done only on the Adrenal Data and not on auxiliary data.\n",
    "    search = GridSearchCV(pipeline_EN,\n",
    "                      param_grid_EN,\n",
    "                      cv=inner_kf,\n",
    "                      scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_parameter = search.best_params_\n",
    "    coefficients = search.best_estimator_.named_steps['model'].coef_\n",
    "    selected_features = np.array(features)[coefficients != 0]\n",
    "    print(selected_features)\n",
    "    print(\"####################################################################################\")\n",
    "\n",
    "\n",
    "    \n",
    "    # Concatenate the Auxiliary Data after feature selection\n",
    "    \n",
    "    # Pancreas\n",
    "    XX_train = pd.concat([X_train, pancreas_Xtrain])\n",
    "    yy_train = pd.concat([y_train, pancreas_Ytrain])\n",
    "    \n",
    "    # OR\n",
    "    \n",
    "    # Lung\n",
    "    XX_train = pd.concat([X_train, lung_Xtrain])\n",
    "    yy_train = pd.concat([y_train, lung_Ytrain])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Use the selected features for further processing\n",
    "    Xtrain_hyper = XX_train[selected_features]\n",
    "    \n",
    "    # Xvalid is the Adrenal Data that is reserved for testing the best estimator from the hyperparameter tuning.\n",
    "    Xvalid = X_test[selected_features] \n",
    "    \n",
    "    # Data Augmentation - BorderlineSMOTE-1 \n",
    "    bsmote = BorderlineSMOTE(random_state=10, kind='borderline-1',k_neighbors=3, sampling_strategy='minority')\n",
    "    X_resampled, y_resampled = bsmote.fit_resample(Xtrain_hyper, y_train)\n",
    "    \n",
    "    \n",
    "    # Hyperparameter Tuning\n",
    "    grid_kf = {}\n",
    "    for name, pipeline in pipelines.items():\n",
    "        grid_search_inner_kf = GridSearchCV(estimator=pipeline,\n",
    "                                            param_grid=params[name],\n",
    "                                            scoring=\"roc_auc\",\n",
    "                                            n_jobs=-1,\n",
    "                                            cv=inner_kf,\n",
    "                                            verbose=0,\n",
    "                                            refit=True)\n",
    "        grid_kf[name] = grid_search_inner_kf\n",
    "\n",
    "    for name, grid_search in grid_kf.items():\n",
    "        grid_kf[name].fit(X_resampled, y_resampled)\n",
    "        best_estimator = grid_kf[name].best_estimator_\n",
    "        ypred = grid_kf[name].best_estimator_.predict(Xvalid_hyper)\n",
    "        \n",
    "        # Check for empty and unique predictions\n",
    "        if ypred is not None:  \n",
    "            unique_classes = np.unique(ypred)\n",
    "            if len(unique_classes) == 1:\n",
    "                print(f\"Skip: Estimator from '{name}' predicts only one class.\")\n",
    "                continue  # Skip to the next iteration\n",
    "\n",
    "            score = roc_auc_score(ypred, y_test)\n",
    "            print(\"estimator:\", best_estimator)\n",
    "            print('estimator_score: ', score)\n",
    "            print(\"-\" * 100)\n",
    "            # Save the best estimator, its score and the selected features in the outer list- best estimator\n",
    "        best_estimators.append({'Algorithm' : name, 'selected_features': selected_features, 'estimator': best_estimator, 'score': score})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9ac914",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850977e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter best estimators of each classifier's results\n",
    "classifier_results = [estimator for estimator in best_estimators if estimator['Algorithm'] == 'DT']\n",
    "\n",
    "# best estimator is the estimator with the highest AUC on the Adrenal validation fold\n",
    "best_estimator = max(classifier_results, key=lambda x: x['score'])\n",
    "best_features = best_estimator_score['selected_features']\n",
    "clf = best_estimator['estimator']\n",
    "\n",
    "#Update Data\n",
    "\n",
    "Adrenal_Xtrain = Adrenal_Xtrain[best_features]\n",
    "lung_Xtrain = lung_Xtrain[best_features]\n",
    "pancreas_Xtrain = pancreas_Xtrain[best_features]\n",
    "\n",
    "# Correlation Matrix\n",
    "corr_matrix = Adrenal_Xtrain.corr(method='pearson')\n",
    "sns.set(style=\"white\")\n",
    "plt.figure(figsize=(20,20)) \n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Heatmap')\n",
    "\n",
    "# Model Evaluation \n",
    "\n",
    "model_kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "outer_scores_auc = []\n",
    "outer_scores_acc = []\n",
    "outer_scores_f1 = []\n",
    "outer_scores_ppv = []\n",
    "outer_scores_npv = []\n",
    "\n",
    "for train_idx, valid_idx in model_kf.split(Adrenal_Xtrain, Adrenal_Ytrain):\n",
    "    X_train, X_valid = Adrenal_Xtrain.iloc[train_idx], Adrenal_Xtrain.iloc[valid_idx]\n",
    "    y_train, y_valid = Adrenal_Ytrain.iloc[train_idx], Adrenal_Ytrain.iloc[valid_idx]\n",
    "    \n",
    "    # Concatenate Auxiliary Data\n",
    "    X_train = pd.concat([X_train, lung_Xtrain])\n",
    "    y_train = pd.concat([y_train, lung_Ytrain])\n",
    "    \n",
    "    X_train = pd.concat([X_train, pancreas_Xtrain])\n",
    "    y_train = pd.concat([y_train, pancreas_Ytrain])\n",
    "    \n",
    "\n",
    "    bsmote = BorderlineSMOTE(random_state=10, kind='borderline-1',k_neighbors=3, sampling_strategy='minority')\n",
    "    X_resampled, y_resampled = bsmote.fit_resample(X_train, y_train)\n",
    "\n",
    "    clf.fit(X_resampled, y_resampled)\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    \n",
    "    \n",
    "     # metrics\n",
    "    # ROC_AUC\n",
    "    AUC_X = roc_auc_score(y_valid,y_pred)\n",
    "    outer_scores_auc.append(AUC_X)\n",
    "    \n",
    "    #Accuracy\n",
    "    ACC_X = accuracy_score(y_valid,y_pred)\n",
    "    outer_scores_acc.append(ACC_X)\n",
    "    \n",
    "    #f1-score\n",
    "    f1_X = f1_score(y_valid,y_pred)\n",
    "    outer_scores_f1.append(f1_X)\n",
    "    \n",
    "    #Confusion Matrix, PPV, NPV\n",
    "    cm = confusion_matrix(y_valid,y_pred)\n",
    "    TN,FP,FN,TP = cm.ravel()\n",
    "    #PPV\n",
    "    PPV_X = TP / (TP + FP)\n",
    "    outer_scores_ppv.append(PPV_X)\n",
    "    #NPV\n",
    "    NPV_X = TN / (TN + FN)\n",
    "    outer_scores_npv.append(NPV_X)\n",
    "    \n",
    "    \n",
    "print(\"AUC\")   \n",
    "# AUC   \n",
    "print(np.mean(outer_scores_auc))\n",
    "SD_auc = np.std(outer_scores_auc)\n",
    "print(outer_scores_auc)\n",
    "print(SD_auc)\n",
    "\n",
    "print(\"*\"*100)\n",
    "\n",
    "print(\"ACC\")\n",
    "\n",
    "# ACC   \n",
    "print(np.mean(outer_scores_acc))\n",
    "SD_acc = np.std(outer_scores_acc)\n",
    "print(outer_scores_acc)\n",
    "print(SD_acc)\n",
    "\n",
    "print(\"*\"*100)\n",
    "\n",
    "print(\"f1-score\")\n",
    "\n",
    "#f1-score\n",
    "# AUC   \n",
    "print(np.mean(outer_scores_f1))\n",
    "SD_f1 = np.std(outer_scores_f1)\n",
    "print(outer_scores_f1)\n",
    "print(SD_f1)\n",
    "\n",
    "\n",
    "print(\"*\"*100)\n",
    "\n",
    "print(\"PPV\")\n",
    "\n",
    "# PPV \n",
    "print(np.mean(outer_scores_ppv))\n",
    "Sd_ppv = np.std(outer_scores_ppv)\n",
    "print(outer_scores_ppv)\n",
    "print(SD_ppv)\n",
    "\n",
    "\n",
    "print(\"*\"*100)\n",
    "\n",
    "print(\"NPV\")  \n",
    "print(np.mean(outer_scores_npv))\n",
    "SD_npv = np.std(outer_scores_npv)\n",
    "print(outer_scores_npv)\n",
    "print(SD_npv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9710d88b",
   "metadata": {},
   "source": [
    "# External Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de01fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load The data\n",
    "\n",
    "ExternalData = pd.read_excel(\"Path to the Delta features of the external dataset\")\n",
    "\n",
    "External_Xtest = ExternalData[best_features]\n",
    "External_Ytest = ExternalData.iloc[:,1]\n",
    "\n",
    "\n",
    "\n",
    "AdLung_Xtrain = pd.concat([Adrenal_Xtrain, lung_Xtrain])\n",
    "AdLung_Ytrain = pd.concat([Adrenal_Ytrain, lung_Ytrain])\n",
    "\n",
    "bsmote = BorderlineSMOTE(random_state=10, kind='borderline-1', k_neighbors=3, sampling_strategy='minority')\n",
    "X_resampled, y_resampled = bsmote.fit_resample(AdLung_Xtrain,AdLung_Ytrain)\n",
    "\n",
    "clf_DT.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred = clf_DT.predict(mci_Xtest)\n",
    "\n",
    "\n",
    "print(\"*\"*100)\n",
    "# ROC_AUC\n",
    "auc_score = roc_auc_score(External_Ytest, y_pred)\n",
    "print(\"External AUC: \", auc_score)\n",
    "\n",
    "print(\"*\"*100)\n",
    "\n",
    "#Accuracy\n",
    "ACC = accuracy_score(y_pred,External_Ytest)\n",
    "print(\"External ACC: \", ACC)\n",
    "\n",
    "print(\"*\"*100)\n",
    "\n",
    "#f1-score\n",
    "f1 = f1_score(y_pred,External_Ytest)\n",
    "print(\"External f1-score : \", f1)\n",
    "\n",
    "print(\"*\"*100)\n",
    "\n",
    "#Confusion Matrix, PPV, NPV\n",
    "cm = confusion_matrix(y_pred,External_Ytest)\n",
    "TN,FP,FN,TP = cm.ravel()\n",
    "#PPV\n",
    "PPV = TP / (TP + FP)\n",
    "print(\"External PPV: \", PPV)\n",
    "\n",
    "print(\"*\"*100)\n",
    "\n",
    "#NPV\n",
    "NPV = TN / (TN + FN)\n",
    "print(\"External NPV: \", NPV)\n",
    "\n",
    "print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb86312c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e52218e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
